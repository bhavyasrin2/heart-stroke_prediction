# -*- coding: utf-8 -*-
"""hypertension.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15Q6NpiXyG-Ih-DxEvl3eCk_FPXv4PNUr
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data=pd.read_csv("/content/drive/MyDrive/machine learning lab/hypertension/hypertension_data.csv")
data.head()

data.describe()

data.info()

data["sex"].fillna(np.mean(data["sex"]), inplace = True)

data.info()

sns.heatmap(data.corr())

data.hist()

sns.pairplot(data)

from sklearn.linear_model import LinearRegression
model=LinearRegression()
model.fit(data[["trestbps"]].values,data[["chol"]])
result=model.predict(data[["trestbps"]].values)
print(result)
'''
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree=4)
extended=poly.fit_transform(data[["trestbps"]])
model=LinearRegression()
model.fit(extended,data[["chol"]])
result=model.predict(extended)'''

find_ans=model.predict([[145]])
print(find_ans)

from sklearn.metrics import mean_squared_error
error=mean_squared_error(data["chol"],result,squared=False)
print(error)

plt.scatter(data["trestbps"],data["chol"],color='red',marker='*')
plt.plot(data["trestbps"],result,color='blue')

data.drop('fbs',axis=1,inplace=True)
data.drop('restecg',axis=1,inplace=True)
data.drop('oldpeak',axis=1,inplace=True)
data.drop('slope',axis=1,inplace=True)
data.drop('ca',axis=1,inplace=True)
data.drop('thal',axis=1,inplace=True)

data.head()

newdata=data.copy()

newdata["chol"]=model.predict(data[["trestbps"]])

newdata.head()

data["target"].value_counts()

X=data.iloc[:,:-1]
Y=data.iloc[:,-1]

X.shape

Y.shape

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,y_test=train_test_split(X.values,Y,random_state=99)

new_X=newdata.iloc[:,:-1]
new_Y=newdata.iloc[:,-1]
new_X_train,new_X_test,new_Y_train,new_y_test=train_test_split(new_X.values,new_Y,random_state=99)

from sklearn.ensemble import RandomForestClassifier
model1=RandomForestClassifier(criterion="gini",
                             max_depth=8,
                             min_samples_split=10,
                             random_state=5)
model2=RandomForestClassifier(criterion="gini",
                             max_depth=8,
                             min_samples_split=10,
                             random_state=5)

model1.fit(X_train,Y_train)

model2.fit(new_X_train,new_Y_train)

print(model1.feature_importances_)
print(model2.feature_importances_)

Y_pred=model1.predict(X_test)
new_Y_pred=model2.predict(new_X_test)

Y_pred

from sklearn.metrics import confusion_matrix
cf1=confusion_matrix(y_test,Y_pred)
print(cf1)
cf2=confusion_matrix(new_y_test,new_Y_pred)
print(cf2)

from sklearn.metrics import accuracy_score
print(accuracy_score(y_test,Y_pred))
print(accuracy_score(new_y_test,new_Y_pred))

from sklearn.model_selection import cross_val_score
cross_val_score(model,X_train,Y_train,cv=10)

from sklearn.metrics import classification_report
print(classification_report(y_test,Y_pred))
print(classification_report(new_y_test,new_Y_pred))

array=model2.predict([[64.0,0.0,2,130,model.predict([[130]]),187,0]])
 print(array[0])

import pickle

pickle.dump(model,open('iri.pkl','wb'))

pickle.dump(model2,open('iri2.pkl','wb'))

